{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d40ead60",
   "metadata": {},
   "source": [
    "# Veille Technologique - Modele CNN ResNet50 vs Vision Transformers (ViT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dac97b",
   "metadata": {},
   "source": [
    "## Imports et config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ff782df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "75071f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import timm\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a74f45",
   "metadata": {},
   "source": [
    "## Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a287e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet Shape = (1050, 15)\n",
      "DataSet Memory Usage = 0.11 MB\n"
     ]
    }
   ],
   "source": [
    "SOURCES_PATH = \"../Sources/\"\n",
    "CSV_FILE = \"flipkart_com-ecommerce_sample_1050.csv\"\n",
    "CSV_FILEPATH = SOURCES_PATH + CSV_FILE\n",
    "IMG_ROOT = Path(SOURCES_PATH + \"Images/\")\n",
    "\n",
    "df = pd.read_csv(CSV_FILEPATH)\n",
    "\n",
    "print('DataSet Shape = {}'.format(df.shape))\n",
    "print('DataSet Memory Usage = {:.2f} MB'.format(df.memory_usage().sum() / 1024**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d5f9bb",
   "metadata": {},
   "source": [
    "#### Je cree ma colonne avec mes 7 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db3ea73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_simple'] = df['product_category_tree'].apply(lambda x: x.split(' >> ')[0].split('[\"')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c710e88",
   "metadata": {},
   "source": [
    "#### On conserve uniquement les lignes avec des images existantes, mesure de securite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1f1b72a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_exists(row):\n",
    "    return (IMG_ROOT / str(row[\"image\"])).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3553354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de lignes/images: 1050\n"
     ]
    }
   ],
   "source": [
    "df['img_path'] = df['image'].apply(lambda x: IMG_ROOT / str(x))\n",
    "print(\"Nombre total de lignes/images:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aaca52",
   "metadata": {},
   "source": [
    "#### Encodage des labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2aea5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(df['category_simple'].unique())\n",
    "class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "idx_to_class = {i: c for c, i in class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5a8a6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Baby Care', 'Beauty and Personal Care', 'Computers', 'Home Decor & Festive Needs', 'Home Furnishing', 'Kitchen & Dining', 'Watches']\n"
     ]
    }
   ],
   "source": [
    "df['label'] = df['category_simple'].map(class_to_idx)\n",
    "num_classes = len(classes)\n",
    "print(\"Classes:\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0858dd83",
   "metadata": {},
   "source": [
    "## Split train / val / test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b7cb28",
   "metadata": {},
   "source": [
    "#### Stratifier sur la categorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c27a1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.30,\n",
    "    stratify=df[\"label\"],\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eed89f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.50,\n",
    "    stratify=temp_df[\"label\"],\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aab81f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(735, 157, 158)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a23ab9d",
   "metadata": {},
   "source": [
    "## Dataset PyTorch + data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "67467e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0ca68e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],  # ImageNet\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca31ee2",
   "metadata": {},
   "source": [
    "#### Class pour les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5115c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlipkartImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row['img_path']).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = int(row['label'])\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4756e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FlipkartImageDataset(train_df, transform=train_transform)\n",
    "val_dataset   = FlipkartImageDataset(val_df, transform=eval_transform)\n",
    "test_dataset  = FlipkartImageDataset(test_df, transform=eval_transform)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf487d8",
   "metadata": {},
   "source": [
    "## Fonctions utilitaires pour l'entrainement et l'evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "02e036ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, log_every=20):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(loader):\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        if i % log_every == 0:\n",
    "            print(f\"batch {i}/{len(loader)} | loss={loss.item():.3f} | acc={(correct/total):.3f}\")\n",
    "\n",
    "    return running_loss / len(loader.dataset), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fed1c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    return epoch_loss, epoch_acc, np.array(all_labels), np.array(all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72743915",
   "metadata": {},
   "source": [
    "#### Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "73f75e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title=\"\"):\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    axes[0].plot(epochs, history[\"train_loss\"], label=\"Train\")\n",
    "    axes[0].plot(epochs, history[\"val_loss\"],   label=\"Val\")\n",
    "    axes[0].set_title(\"Loss\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(epochs, history[\"train_acc\"], label=\"Train\")\n",
    "    axes[1].plot(epochs, history[\"val_acc\"],   label=\"Val\")\n",
    "    axes[1].set_title(\"Accuracy\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2508a46",
   "metadata": {},
   "source": [
    "## Modele CNN Baseline : ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "59290f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8381ff8",
   "metadata": {},
   "source": [
    "#### On remplace la derniere couche FC par notre tete et on gele le backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ada85a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in resnet.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "38b3518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "29dc414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a46c65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "274a8d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "best_val_acc = 0.0\n",
    "history_resnet = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1d33144c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0/46 | loss=1.957 | acc=0.188\n",
      "batch 20/46 | loss=1.877 | acc=0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 40/46 | loss=1.784 | acc=0.282\n",
      "[ResNet] Epoch 01 | Train loss=1.873, acc=0.302 | Val loss=1.784, acc=0.452\n",
      "batch 0/46 | loss=1.707 | acc=0.688\n",
      "batch 20/46 | loss=1.735 | acc=0.580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 40/46 | loss=1.589 | acc=0.607\n",
      "[ResNet] Epoch 02 | Train loss=1.704, acc=0.614 | Val loss=1.643, acc=0.650\n",
      "batch 0/46 | loss=1.669 | acc=0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 20/46 | loss=1.622 | acc=0.738\n",
      "batch 40/46 | loss=1.506 | acc=0.748\n",
      "[ResNet] Epoch 03 | Train loss=1.552, acc=0.739 | Val loss=1.509, acc=0.720\n",
      "batch 0/46 | loss=1.481 | acc=0.688\n",
      "batch 20/46 | loss=1.348 | acc=0.735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (89777736 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 40/46 | loss=1.545 | acc=0.758\n",
      "[ResNet] Epoch 04 | Train loss=1.431, acc=0.762 | Val loss=1.393, acc=0.764\n",
      "batch 0/46 | loss=1.426 | acc=0.625\n",
      "batch 20/46 | loss=1.289 | acc=0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 40/46 | loss=1.221 | acc=0.796\n",
      "[ResNet] Epoch 05 | Train loss=1.320, acc=0.788 | Val loss=1.310, acc=0.777\n",
      "batch 0/46 | loss=1.110 | acc=0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 20/46 | loss=1.276 | acc=0.807\n",
      "batch 40/46 | loss=1.176 | acc=0.799\n",
      "[ResNet] Epoch 06 | Train loss=1.224, acc=0.795 | Val loss=1.236, acc=0.771\n",
      "batch 0/46 | loss=1.135 | acc=0.750\n",
      "batch 20/46 | loss=1.219 | acc=0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 40/46 | loss=0.894 | acc=0.814\n",
      "[ResNet] Epoch 07 | Train loss=1.136, acc=0.812 | Val loss=1.147, acc=0.783\n",
      "batch 0/46 | loss=1.178 | acc=0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 20/46 | loss=1.107 | acc=0.830\n",
      "batch 40/46 | loss=1.008 | acc=0.808\n",
      "[ResNet] Epoch 08 | Train loss=1.077, acc=0.814 | Val loss=1.099, acc=0.764\n",
      "batch 0/46 | loss=0.986 | acc=0.812\n",
      "batch 20/46 | loss=0.925 | acc=0.810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 40/46 | loss=0.871 | acc=0.811\n",
      "[ResNet] Epoch 09 | Train loss=1.004, acc=0.822 | Val loss=1.042, acc=0.783\n",
      "batch 0/46 | loss=0.971 | acc=0.812\n",
      "batch 20/46 | loss=0.954 | acc=0.804\n",
      "batch 40/46 | loss=1.055 | acc=0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet] Epoch 10 | Train loss=0.961, acc=0.819 | Val loss=1.000, acc=0.796\n",
      "batch 0/46 | loss=0.974 | acc=0.875\n",
      "batch 20/46 | loss=0.835 | acc=0.848\n",
      "batch 40/46 | loss=0.827 | acc=0.826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet] Epoch 11 | Train loss=0.908, acc=0.826 | Val loss=0.961, acc=0.796\n",
      "batch 0/46 | loss=1.046 | acc=0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 20/46 | loss=0.982 | acc=0.810\n",
      "batch 40/46 | loss=0.741 | acc=0.828\n",
      "[ResNet] Epoch 12 | Train loss=0.876, acc=0.824 | Val loss=0.927, acc=0.771\n",
      "batch 0/46 | loss=1.119 | acc=0.625\n",
      "batch 20/46 | loss=0.747 | acc=0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 40/46 | loss=0.849 | acc=0.817\n",
      "[ResNet] Epoch 13 | Train loss=0.850, acc=0.811 | Val loss=0.894, acc=0.796\n",
      "batch 0/46 | loss=0.766 | acc=0.875\n",
      "batch 20/46 | loss=0.729 | acc=0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 40/46 | loss=0.797 | acc=0.822\n",
      "[ResNet] Epoch 14 | Train loss=0.811, acc=0.827 | Val loss=0.868, acc=0.790\n",
      "batch 0/46 | loss=0.855 | acc=0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cosic\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 20/46 | loss=0.819 | acc=0.830\n",
      "batch 40/46 | loss=0.876 | acc=0.829\n",
      "[ResNet] Epoch 15 | Train loss=0.761, acc=0.835 | Val loss=0.846, acc=0.790\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = train_one_epoch(resnet, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc, _, _ = evaluate(resnet, val_loader, criterion)\n",
    "\n",
    "    history_resnet[\"train_loss\"].append(train_loss)\n",
    "    history_resnet[\"val_loss\"].append(val_loss)\n",
    "    history_resnet[\"train_acc\"].append(train_acc)\n",
    "    history_resnet[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    print(f\"[ResNet] Epoch {epoch:02d} | \"\n",
    "          f\"Train loss={train_loss:.3f}, acc={train_acc:.3f} | \"\n",
    "          f\"Val loss={val_loss:.3f}, acc={val_acc:.3f}\")\n",
    "\n",
    "    # on arrete de maniere anticipee \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(resnet.state_dict(), \"resnet50_best.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f005c561",
   "metadata": {},
   "source": [
    "#### A lancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_resnet, title=\"ResNet50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1a43d",
   "metadata": {},
   "source": [
    "## Vision Transformer (ViT-B/16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit = timm.create_model(\n",
    "    \"vit_base_patch16_224\",\n",
    "    pretrained=True,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "vit = vit.to(device)\n",
    "\n",
    "criterion_vit = nn.CrossEntropyLoss()\n",
    "optimizer_vit = optim.AdamW(vit.parameters(), lr=2e-5, weight_decay=1e-4)\n",
    "\n",
    "EPOCHS_VIT = 15\n",
    "best_val_acc_vit = 0.0\n",
    "history_vit = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "for epoch in range(1, EPOCHS_VIT + 1):\n",
    "    train_loss, train_acc = train_one_epoch(vit, train_loader, criterion_vit, optimizer_vit)\n",
    "    val_loss, val_acc, _, _ = evaluate(vit, val_loader, criterion_vit)\n",
    "\n",
    "    history_vit[\"train_loss\"].append(train_loss)\n",
    "    history_vit[\"val_loss\"].append(val_loss)\n",
    "    history_vit[\"train_acc\"].append(train_acc)\n",
    "    history_vit[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    print(f\"[ViT] Epoch {epoch:02d} | \"\n",
    "          f\"Train loss={train_loss:.3f}, acc={train_acc:.3f} | \"\n",
    "          f\"Val loss={val_loss:.3f}, acc={val_acc:.3f}\")\n",
    "\n",
    "    if val_acc > best_val_acc_vit:\n",
    "        best_val_acc_vit = val_acc\n",
    "        torch.save(vit.state_dict(), \"vit_base_patch16_224_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b5b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_vit, title=\"ViT-B/16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918bd9d4",
   "metadata": {},
   "source": [
    "## Évaluation finale sur le test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c575c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les meilleurs poids\n",
    "resnet.load_state_dict(torch.load(\"resnet50_best.pth\", map_location=device))\n",
    "vit.load_state_dict(torch.load(\"vit_base_patch16_224_best.pth\", map_location=device))\n",
    "\n",
    "# ResNet\n",
    "test_loss_r, test_acc_r, y_true_r, y_pred_r = evaluate(resnet, test_loader, criterion)\n",
    "print(f\"ResNet50 - Test loss={test_loss_r:.3f}, acc={test_acc_r:.3f}\")\n",
    "print(classification_report(y_true_r, y_pred_r, target_names=classes))\n",
    "\n",
    "# ViT\n",
    "test_loss_v, test_acc_v, y_true_v, y_pred_v = evaluate(vit, test_loader, criterion_vit)\n",
    "print(f\"ViT-B/16 - Test loss={test_loss_v:.3f}, acc={test_acc_v:.3f}\")\n",
    "print(classification_report(y_true_v, y_pred_v, target_names=classes))\n",
    "\n",
    "# Matrices de confusion\n",
    "def plot_confusion(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel(\"Prédit\")\n",
    "    plt.ylabel(\"Vrai\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion(y_true_r, y_pred_r, \"Matrice de confusion - ResNet50\")\n",
    "plot_confusion(y_true_v, y_pred_v, \"Matrice de confusion - ViT-B/16\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
